# LLaMA3-DPO-Alignment
An end-to-end toolkit for aligning LLaMA-3 models using Direct Preference Optimization (DPO), including scripts for training and inference.
